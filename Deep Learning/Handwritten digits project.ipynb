{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5e172e38",
   "metadata": {},
   "source": [
    "# Deep Neural Network for MNIST Classification\n",
    "\n",
    "We'll apply all the knowledge from the lectures in this section to write a deep neural network. The problem we've chosen is referred to as the \"Hello World\" of deep learning because for most students it is the first deep learning algorithm they see.\n",
    "\n",
    "The dataset is called MNIST and refers to handwritten digit recognition. You can find more about it on Yann LeCun's website (Director of AI Research, Facebook). He is one of the pioneers of what we've been talking about and of more complex approaches that are widely used today, such as covolutional neural networks (CNNs). \n",
    "\n",
    "The dataset provides 70,000 images (28x28 pixels) of handwritten digits (1 digit per image). \n",
    "\n",
    "The goal is to write an algorithm that detects which digit is written. Since there are only 10 digits (0, 1, 2, 3, 4, 5, 6, 7, 8, 9), this is a classification problem with 10 classes. \n",
    "\n",
    "Our goal would be to build a neural network with 2 hidden layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "65bbbe78",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-18 11:06:41.671900: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-10-18 11:06:42.188777: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-10-18 11:06:42.188797: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2023-10-18 11:06:43.506304: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-10-18 11:06:43.506407: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-10-18 11:06:43.506417: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eacfcef8",
   "metadata": {},
   "source": [
    "# prepare our data and preprocess it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ca5d281e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-14 10:12:06.954036: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-10-14 10:12:06.955199: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/abdelmoneim/anaconda3/lib/python3.9/site-packages/cv2/../../lib64:\n",
      "2023-10-14 10:12:06.955675: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublas.so.11'; dlerror: libcublas.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/abdelmoneim/anaconda3/lib/python3.9/site-packages/cv2/../../lib64:\n",
      "2023-10-14 10:12:06.955859: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublasLt.so.11'; dlerror: libcublasLt.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/abdelmoneim/anaconda3/lib/python3.9/site-packages/cv2/../../lib64:\n",
      "2023-10-14 10:12:06.956029: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcufft.so.10'; dlerror: libcufft.so.10: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/abdelmoneim/anaconda3/lib/python3.9/site-packages/cv2/../../lib64:\n",
      "2023-10-14 10:12:06.956200: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcurand.so.10'; dlerror: libcurand.so.10: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/abdelmoneim/anaconda3/lib/python3.9/site-packages/cv2/../../lib64:\n",
      "2023-10-14 10:12:06.956506: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusolver.so.11'; dlerror: libcusolver.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/abdelmoneim/anaconda3/lib/python3.9/site-packages/cv2/../../lib64:\n",
      "2023-10-14 10:12:06.956679: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusparse.so.11'; dlerror: libcusparse.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/abdelmoneim/anaconda3/lib/python3.9/site-packages/cv2/../../lib64:\n",
      "2023-10-14 10:12:06.956846: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/abdelmoneim/anaconda3/lib/python3.9/site-packages/cv2/../../lib64:\n",
      "2023-10-14 10:12:06.956873: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1934] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2023-10-14 10:12:06.958821: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-10-14 10:12:07.769893: W tensorflow/core/kernels/data/cache_dataset_ops.cc:856] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    }
   ],
   "source": [
    "mnist_dataset, mnist_info = tfds.load(name = 'mnist', with_info = True, as_supervised = True)\n",
    "mnist_train, mnist_test = mnist_dataset['train'], mnist_dataset['test']\n",
    "\n",
    "num_validation_samples = 0.1 * mnist_info.splits['train'].num_examples\n",
    "num_validation_samples = tf.cast(num_validation_samples, tf.int64)\n",
    "\n",
    "num_test_samples = mnist_info.splits['test'].num_examples\n",
    "num_test_samples = tf.cast(num_test_samples, tf.int64)\n",
    "\n",
    "def scale(image, label):\n",
    "    image = tf.cast(image, tf.float32)\n",
    "    image /=255.\n",
    "    return image,label\n",
    "\n",
    "scaled_train_validation_data = mnist_train.map(scale)\n",
    "test_data = mnist_test.map(scale)\n",
    "\n",
    "buffer_size = 10000\n",
    "shuffle_train_validation_data = scaled_train_validation_data.shuffle(buffer_size)\n",
    "\n",
    "validation_data = shuffle_train_validation_data.take(num_validation_samples)\n",
    "train_data = shuffle_train_validation_data.skip(num_validation_samples)\n",
    "\n",
    "batch_size = 32\n",
    "train_data = train_data.batch(batch_size)\n",
    "validation_data = validation_data.batch(num_validation_samples)\n",
    "test_data = test_data.batch(num_test_samples)\n",
    "\n",
    "validation_inputs, validation_targets = next(iter(validation_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d668ef07",
   "metadata": {},
   "source": [
    "## outline model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d60c7ad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 784\n",
    "output_size = 10\n",
    "hidden_layers = 128\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "                                #convloution step\n",
    "                                tf.keras.layers.Conv2D(filters = 32, kernel_size = 3, activation = 'relu', input_shape = [28,28,1]),\n",
    "                                \n",
    "                                #pooling step\n",
    "                                tf.keras.layers.MaxPool2D(pool_size = 2, strides = 2),\n",
    "                \n",
    "                                #adding a second convolutional layer\n",
    "                                tf.keras.layers.Conv2D(filters = 32, kernel_size = 3, activation = 'relu', input_shape = [28,28,1]),\n",
    "                                tf.keras.layers.MaxPool2D(pool_size = 2, strides = 2),\n",
    "    \n",
    "                                #adding a third convolutional layer\n",
    "                                tf.keras.layers.Conv2D(filters = 32, kernel_size = 3, activation = 'relu', input_shape = [28,28,1]),\n",
    "                                tf.keras.layers.MaxPool2D(pool_size = 2, strides = 2),\n",
    "    \n",
    "                                #flattening\n",
    "                                tf.keras.layers.Flatten(),\n",
    "    \n",
    "                                #full connection\n",
    "                                tf.keras.layers.Dense(hidden_layers, activation = 'relu'),\n",
    "                                #output layer\n",
    "                                tf.keras.layers.Dense(output_size, activation = 'softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cb3ca275",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer = 'adam',loss='sparse_categorical_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19b57cd9",
   "metadata": {},
   "source": [
    "## training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ebf01b51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1688/1688 - 30s - loss: 0.2907 - accuracy: 0.9087 - val_loss: 0.1330 - val_accuracy: 0.9605 - 30s/epoch - 18ms/step\n",
      "Epoch 2/10\n",
      "1688/1688 - 25s - loss: 0.1054 - accuracy: 0.9676 - val_loss: 0.0863 - val_accuracy: 0.9728 - 25s/epoch - 15ms/step\n",
      "Epoch 3/10\n",
      "1688/1688 - 28s - loss: 0.0764 - accuracy: 0.9763 - val_loss: 0.0621 - val_accuracy: 0.9808 - 28s/epoch - 17ms/step\n",
      "Epoch 4/10\n",
      "1688/1688 - 29s - loss: 0.0632 - accuracy: 0.9805 - val_loss: 0.0646 - val_accuracy: 0.9798 - 29s/epoch - 17ms/step\n",
      "Epoch 5/10\n",
      "1688/1688 - 28s - loss: 0.0528 - accuracy: 0.9833 - val_loss: 0.0491 - val_accuracy: 0.9855 - 28s/epoch - 17ms/step\n",
      "Epoch 6/10\n",
      "1688/1688 - 27s - loss: 0.0447 - accuracy: 0.9866 - val_loss: 0.0454 - val_accuracy: 0.9865 - 27s/epoch - 16ms/step\n",
      "Epoch 7/10\n",
      "1688/1688 - 29s - loss: 0.0384 - accuracy: 0.9876 - val_loss: 0.0368 - val_accuracy: 0.9883 - 29s/epoch - 17ms/step\n",
      "Epoch 8/10\n",
      "1688/1688 - 28s - loss: 0.0340 - accuracy: 0.9891 - val_loss: 0.0314 - val_accuracy: 0.9907 - 28s/epoch - 17ms/step\n",
      "Epoch 9/10\n",
      "1688/1688 - 25s - loss: 0.0304 - accuracy: 0.9899 - val_loss: 0.0309 - val_accuracy: 0.9907 - 25s/epoch - 15ms/step\n",
      "Epoch 10/10\n",
      "1688/1688 - 24s - loss: 0.0268 - accuracy: 0.9911 - val_loss: 0.0215 - val_accuracy: 0.9925 - 24s/epoch - 14ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fdeac63cb20>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_data,epochs = 10,validation_data = (validation_inputs,validation_targets),verbose = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8973e0cc",
   "metadata": {},
   "source": [
    "## testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ab411e42",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-14 10:17:09.788209: W tensorflow/tsl/framework/cpu_allocator_impl.cc:82] Allocation of 865280000 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 863ms/step - loss: 0.0438 - accuracy: 0.9879\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_accuracy = model.evaluate(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1497c01b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.04. Test accuracy: 98.79%\n"
     ]
    }
   ],
   "source": [
    "print('Test loss: {0:.2f}. Test accuracy: {1:.2f}%'.format(test_loss, test_accuracy*100.))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "085f7270",
   "metadata": {},
   "source": [
    "**Thank you**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
