{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a22a9385",
   "metadata": {},
   "source": [
    "# Problem\n",
    "You are given data from an Audiobook app. Logically, it relates only to the audio versions of books. Each customer in the database has made a purchase at least once, that's why he/she is in the database. We want to create a machine learning algorithm based on our available data that can predict if a customer will buy again from the Audiobook company.\n",
    "\n",
    "The main idea is that if a customer has a low probability of coming back, there is no reason to spend any money on advertizing to him/her. If we can focus our efforts ONLY on customers that are likely to convert again, we can make great savings. Moreover, this model can identify the most important metrics for a customer to come back again. Identifying new customers creates value and growth opportunities.\n",
    "\n",
    "You have a .csv summarizing the data. There are several variables: Customer ID, Book length in mins_avg (average of all purchases), Book length in minutes_sum (sum of all purchases), Price Paid_avg (average of all purchases), Price paid_sum (sum of all purchases), Review (a Boolean variable), Review (out of 10), Total minutes listened, Completion (from 0 to 1), Support requests (number), and Last visited minus purchase date (in days).\n",
    "\n",
    "So these are the inputs (excluding customer ID, as it is completely arbitrary. It's more like a name, than a number).\n",
    "\n",
    "The targets are a Boolean variable (so 0, or 1). We are taking a period of 2 years in our inputs, and the next 6 months as targets. So, in fact, we are predicting if: based on the last 2 years of activity and engagement, a customer will convert in the next 6 months. 6 months sounds like a reasonable time. If they don't convert after 6 months, chances are they've gone to a competitor or didn't like the Audiobook way of digesting information.\n",
    "\n",
    "The task is simple: create a machine learning algorithm, which is able to predict if a customer will buy again.\n",
    "\n",
    "This is a classification problem with two classes: won't buy and will buy, represented by 0s and 1s.\n",
    "\n",
    "Good luck! "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92ace070",
   "metadata": {},
   "source": [
    "## preprocess the data\n",
    "    Balance the dataset\n",
    "    standardize the inputs\n",
    "    shuffle the data\n",
    "    divide the dataset in trainig,validation and test\n",
    "    save the data in a tensor friendly format (npz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1272ad40",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-30 12:32:06.608730: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-08-30 12:32:06.782896: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-08-30 12:32:06.782922: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2023-08-30 12:32:07.539243: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-08-30 12:32:07.539317: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-08-30 12:32:07.539326: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn import preprocessing \n",
    "import tensorflow as tf\n",
    "\n",
    "raw_data = np.loadtxt('Audiobooks_data.csv',delimiter = ',')\n",
    "unscaled_inputs = raw_data[:,1:-1]\n",
    "targets_all = raw_data[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "691d7bd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_ones = int(np.sum(targets_all))\n",
    "count_zero = 0\n",
    "remove_indecies = []\n",
    "\n",
    "for i in range(targets_all.shape[0]):\n",
    "    if(targets_all[i] == 0):\n",
    "        count_zero +=1\n",
    "    if(count_zero > count_ones):\n",
    "        remove_indecies.append(i)\n",
    "\n",
    "unscaled_input = np.delete(unscaled_inputs,remove_indecies,axis = 0)\n",
    "target_all = np.delete(targets_all,remove_indecies,axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "74097ea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_input = preprocessing.scale(unscaled_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c12f5fb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_shuffles = np.arange(scaled_input.shape[0])\n",
    "np.random.shuffle(num_shuffles)\n",
    "\n",
    "shuffled_inputs = scaled_input[num_shuffles]\n",
    "shuffled_targets = target_all[num_shuffles]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "77f80806",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_samples = shuffled_inputs.shape[0]\n",
    "\n",
    "train_samples = int(0.8 * num_samples)\n",
    "validation_samples = int(0.1 * num_samples)\n",
    "test_samples = num_samples - train_samples - validation_samples\n",
    "\n",
    "train_inputs = shuffled_inputs[:train_samples]\n",
    "train_targets = shuffled_targets[:train_samples]\n",
    "\n",
    "validation_inputs = shuffled_inputs[train_samples:train_samples + validation_samples]\n",
    "validation_targets = shuffled_targets[train_samples:train_samples + validation_samples]\n",
    "\n",
    "test_inputs = shuffled_inputs[train_samples + validation_samples:]\n",
    "test_targets = shuffled_targets[train_samples + validation_samples:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b1151080",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez('Audio_books_data_train',inputs = train_inputs,targets = train_targets)\n",
    "np.savez('Audio_books_data_validate',inputs = validation_inputs,targets = validation_targets)\n",
    "np.savez('Audio_books_data_test',inputs = test_inputs,targets = test_targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc54ec08",
   "metadata": {},
   "source": [
    "## create a machine learning algorithm\n",
    "    outline the model\n",
    "    compile model \n",
    "    fit model\n",
    "    test model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2b6696c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_70693/311491798.py:2: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  tarining_input = npz['inputs'].astype(np.float)\n",
      "/tmp/ipykernel_70693/311491798.py:3: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  tarining_target = npz['targets'].astype(np.int)\n",
      "/tmp/ipykernel_70693/311491798.py:6: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  validate_input = npz['inputs'].astype(np.float)\n",
      "/tmp/ipykernel_70693/311491798.py:7: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  validate_target = npz['targets'].astype(np.int)\n",
      "/tmp/ipykernel_70693/311491798.py:10: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  test_input = npz['inputs'].astype(np.float)\n",
      "/tmp/ipykernel_70693/311491798.py:11: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  test_target = npz['targets'].astype(np.int)\n"
     ]
    }
   ],
   "source": [
    "npz = np.load('Audio_books_data_train.npz')\n",
    "tarining_input = npz['inputs'].astype(np.float)\n",
    "tarining_target = npz['targets'].astype(np.int)\n",
    "\n",
    "npz = np.load('Audio_books_data_validate.npz')\n",
    "validate_input = npz['inputs'].astype(np.float)\n",
    "validate_target = npz['targets'].astype(np.int)\n",
    "\n",
    "npz = np.load('Audio_books_data_test.npz')\n",
    "test_input = npz['inputs'].astype(np.float)\n",
    "test_target = npz['targets'].astype(np.int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e8a249f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 10\n",
    "output_size = 2\n",
    "hidden_layers_size = 50\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Dense(hidden_layers_size,activation = 'relu'),\n",
    "        tf.keras.layers.Dense(hidden_layers_size,activation = 'relu'),\n",
    "    \n",
    "        tf.keras.layers.Dense(output_size,activation = 'softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "37c7e709",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer = 'adam',loss = 'sparse_categorical_crossentropy',metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3bb49cb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "36/36 - 1s - loss: 0.5676 - accuracy: 0.7631 - val_loss: 0.4027 - val_accuracy: 0.8881 - 732ms/epoch - 20ms/step\n",
      "Epoch 2/100\n",
      "36/36 - 0s - loss: 0.3734 - accuracy: 0.8726 - val_loss: 0.2933 - val_accuracy: 0.9038 - 69ms/epoch - 2ms/step\n",
      "Epoch 3/100\n",
      "36/36 - 0s - loss: 0.3235 - accuracy: 0.8785 - val_loss: 0.2743 - val_accuracy: 0.9060 - 68ms/epoch - 2ms/step\n",
      "Epoch 4/100\n",
      "36/36 - 0s - loss: 0.3042 - accuracy: 0.8866 - val_loss: 0.2603 - val_accuracy: 0.9128 - 68ms/epoch - 2ms/step\n",
      "Epoch 5/100\n",
      "36/36 - 0s - loss: 0.2913 - accuracy: 0.8908 - val_loss: 0.2511 - val_accuracy: 0.9172 - 67ms/epoch - 2ms/step\n",
      "Epoch 6/100\n",
      "36/36 - 0s - loss: 0.2815 - accuracy: 0.8941 - val_loss: 0.2450 - val_accuracy: 0.9128 - 66ms/epoch - 2ms/step\n",
      "Epoch 7/100\n",
      "36/36 - 0s - loss: 0.2740 - accuracy: 0.8966 - val_loss: 0.2378 - val_accuracy: 0.9150 - 66ms/epoch - 2ms/step\n",
      "Epoch 8/100\n",
      "36/36 - 0s - loss: 0.2660 - accuracy: 0.8963 - val_loss: 0.2387 - val_accuracy: 0.9128 - 66ms/epoch - 2ms/step\n",
      "Epoch 9/100\n",
      "36/36 - 0s - loss: 0.2634 - accuracy: 0.9005 - val_loss: 0.2333 - val_accuracy: 0.9217 - 64ms/epoch - 2ms/step\n",
      "Epoch 10/100\n",
      "36/36 - 0s - loss: 0.2582 - accuracy: 0.9014 - val_loss: 0.2272 - val_accuracy: 0.9172 - 64ms/epoch - 2ms/step\n",
      "Epoch 11/100\n",
      "36/36 - 0s - loss: 0.2561 - accuracy: 0.9019 - val_loss: 0.2229 - val_accuracy: 0.9172 - 70ms/epoch - 2ms/step\n",
      "Epoch 12/100\n",
      "36/36 - 0s - loss: 0.2521 - accuracy: 0.9042 - val_loss: 0.2266 - val_accuracy: 0.9195 - 64ms/epoch - 2ms/step\n",
      "Epoch 13/100\n",
      "36/36 - 0s - loss: 0.2489 - accuracy: 0.9036 - val_loss: 0.2253 - val_accuracy: 0.9195 - 64ms/epoch - 2ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f2ddc4789a0>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "early_stop = tf.keras.callbacks.EarlyStopping(patience=2)\n",
    "model.fit(tarining_input,\n",
    "          tarining_target, \n",
    "          batch_size=100, \n",
    "          epochs=100,\n",
    "          callbacks=[early_stop], \n",
    "          validation_data=(validate_input, validate_target), \n",
    "          verbose = 2 \n",
    "          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "29efea6c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 0s 2ms/step - loss: 0.2469 - accuracy: 0.9018\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.24687887728214264, 0.9017857313156128]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test_input,test_target)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
